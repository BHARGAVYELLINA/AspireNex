{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a79e45e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be18004a-f8aa-4390-bc3b-06938bb0b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"handwritten_text_generator.h5\"):\n",
    "    def load_image_paths(directory):\n",
    "        image_paths = []\n",
    "        for root, _, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                if file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    image_paths.append(os.path.join(root, file))\n",
    "        return image_paths\n",
    "\n",
    "    train_image_paths = load_image_paths('train_v2')\n",
    "    test_image_paths = load_image_paths('test_v2')\n",
    "    validation_image_paths = load_image_paths('validation_v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2b03f7a-2a73-4a51-b08b-9fdd7b86678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"handwritten_text_generator.h5\"):\n",
    "    def load_data(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        return dict(zip(df['FILENAME'], df['IDENTITY']))\n",
    "\n",
    "    train_texts = load_data('written_name_train_v2.csv')\n",
    "    test_texts = load_data('written_name_test_v2.csv')\n",
    "    validation_texts = load_data('written_name_validation_v2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "630307f3-8bf3-4bf2-81c4-64abf8a232c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"handwritten_text_generator.h5\"):\n",
    "    def create_image_text_pairs(image_paths, texts):\n",
    "        pairs = []\n",
    "        for path in image_paths:\n",
    "            file_name = os.path.basename(path)\n",
    "            if file_name in texts:\n",
    "                pairs.append((path, texts[file_name]))\n",
    "        return pairs\n",
    "\n",
    "    train_pairs = create_image_text_pairs(train_image_paths, train_texts)\n",
    "    test_pairs = create_image_text_pairs(test_image_paths, test_texts)\n",
    "    validation_pairs = create_image_text_pairs(validation_image_paths, validation_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71884df9-715d-4ed4-a2d1-0128c0cdab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, target_size=(128, 32)):\n",
    "        image = load_img(image_path, color_mode='grayscale', target_size=target_size)\n",
    "        image = img_to_array(image) / 255.0\n",
    "        return image\n",
    "\n",
    "if not os.path.exists(\"handwritten_text_generator.h5\"):\n",
    "\n",
    "    train_images = np.array([preprocess_image(path) for path, _ in train_pairs])\n",
    "    test_images = np.array([preprocess_image(path) for path, _ in test_pairs])\n",
    "    validation_images = np.array([preprocess_image(path) for path, _ in validation_pairs])\n",
    "\n",
    "    train_texts = [text for _, text in train_pairs]\n",
    "    test_texts = [text for _, text in test_pairs]\n",
    "    validation_texts = [text for _, text in validation_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92fe5246-0cb1-4afc-8f0d-eb0aee4b58d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"handwritten_text_generator.h5\") or not os.path.exists(\"tokenizer.pickle\"):\n",
    "    def filter_non_string_texts(texts):\n",
    "        return [text for text in texts if isinstance(text, str)]\n",
    "\n",
    "    train_texts = filter_non_string_texts(train_texts)\n",
    "    test_texts = filter_non_string_texts(test_texts)\n",
    "    validation_texts = filter_non_string_texts(validation_texts)\n",
    "\n",
    "    tokenizer = Tokenizer(char_level=True)\n",
    "    tokenizer.fit_on_texts(train_texts)\n",
    "    total_chars = len(tokenizer.word_index) + 1\n",
    "\n",
    "    with open('tokenizer.pickle', 'wb') as handle:\n",
    "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "\n",
    "    def create_dataset(sequences, images, step=1):\n",
    "        X_text = []\n",
    "        X_image = []\n",
    "        y = []\n",
    "        for i, seq in enumerate(sequences):\n",
    "            for j in range(0, len(seq) - step, step):\n",
    "                X_text.append(seq[j:j+step])\n",
    "                X_image.append(images[i])\n",
    "                y.append(seq[j+step])\n",
    "        return np.array(X_text), np.array(X_image), np.array(y)\n",
    "\n",
    "    step = 5\n",
    "    X_text, X_image, y = create_dataset(train_sequences, train_images, step)\n",
    "\n",
    "    input_text = tf.keras.layers.Input(shape=(step,))\n",
    "    input_image = tf.keras.layers.Input(shape=(128, 32, 1))\n",
    "\n",
    "    x_text = Embedding(total_chars, 50)(input_text)\n",
    "    x_text = LSTM(128, return_sequences=True)(x_text)\n",
    "    x_text = LSTM(128)(x_text)\n",
    "\n",
    "    x_image = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(input_image)\n",
    "    x_image = tf.keras.layers.MaxPooling2D((2, 2))(x_image)\n",
    "    x_image = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x_image)\n",
    "    x_image = tf.keras.layers.MaxPooling2D((2, 2))(x_image)\n",
    "    x_image = tf.keras.layers.Flatten()(x_image)\n",
    "    x_image = tf.keras.layers.Dense(128, activation='relu')(x_image)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate()([x_text, x_image])\n",
    "    output = tf.keras.layers.Dense(total_chars, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[input_text, input_image], outputs=output)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c3ec167-8526-4119-89e8-0704e8e440f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"handwritten_text_generator.h5\"):\n",
    "    model.fit([X_text, X_image], y, epochs=20, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ba24956",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"handwritten_text_generator.h5\"):\n",
    "    model.save('handwritten_text_generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4869f093-77cf-4c07-ae4b-001812f366c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examplet\n"
     ]
    }
   ],
   "source": [
    "model = load_model('handwritten_text_generator.h5')\n",
    "\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "def generate_text(model, tokenizer, seed_text, num_chars, image, step=5):\n",
    "    result = seed_text\n",
    "    for _ in range(num_chars):\n",
    "        sequence = tokenizer.texts_to_sequences([result])[-1]\n",
    "        sequence = pad_sequences([sequence], maxlen=step, padding='pre')\n",
    "        predicted = model.predict([sequence, np.expand_dims(image, axis=0)], verbose=0)\n",
    "        predicted_char_index = np.argmax(predicted)\n",
    "        predicted_char = tokenizer.index_word.get(predicted_char_index, '')\n",
    "        if predicted_char:\n",
    "            result += predicted_char\n",
    "        else:\n",
    "            break\n",
    "    return result\n",
    "\n",
    "seed_text = \"example\"\n",
    "num_chars = 100\n",
    "image = preprocess_image('validation_v2\\\\validation\\\\VALIDATION_0022.jpg')\n",
    "generated_text = generate_text(model, tokenizer, seed_text, num_chars, image)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf787263-792f-4345-b6c8-f50f7bb0a70d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
